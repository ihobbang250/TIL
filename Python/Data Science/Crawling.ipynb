{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "환율계산기\n",
      "--------------------------------\n",
      "\n",
      "미국 USD : 1,238.50원\n",
      "일본 JPY(100엔) : 963.40원\n",
      "유럽연합 EUR : 1,339.19원\n",
      "중국 CNY : 183.94원\n",
      "달러/일본 엔 : 127.8500원\n",
      "유로/달러 : 1.0832원\n",
      "영국 파운드/달러 : 1.2228원\n",
      "달러인덱스 : 101.9400원\n",
      "WTI : 79.86원\n",
      "휘발유 : 1559.83원\n",
      "국제 금 : 1921.7원\n",
      "국내 금 : 76127.25원\n",
      "\n",
      "8.1달러로 환전\n"
     ]
    }
   ],
   "source": [
    "# requests text 데이터 받아와 원하는 문자열 추출\n",
    "import requests as req\n",
    "import re\n",
    "\n",
    "res = req.get(\"https://finance.naver.com/marketindex/?tabSel=exchange#tab_section\")\n",
    "\n",
    "body = res.text\n",
    "\n",
    "r = re.compile(r\"h_lst.*?blind\\\">(.*?)</span>.*?value\\\">(.*?)</\", re.DOTALL)\n",
    "captures = r.findall(body)\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "print(\"환율계산기\")\n",
    "print(\"--------------------------------\")\n",
    "print(\"\")\n",
    "\n",
    "for c in captures:\n",
    "    print(f\"{c[0]} : {c[1]}원\")\n",
    "\n",
    "print()\n",
    "usd = float(captures[0][1].replace(\",\", \"\"))\n",
    "won = int(input(\"달러로 바꾸길 원하는 금액(원) 입력해주세요: \"))\n",
    "dollar = round((won / usd), 1)\n",
    "print(f\"{dollar}달러로 환전\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['미국 USD', '유럽연합 EUR', '일본 JPY (100엔)', '중국 CNY', '홍콩 HKD', '대만 TWD', '영국 GBP', '오만 OMR', '캐나다 CAD', '스위스 CHF', '스웨덴 SEK', '호주 AUD', '뉴질랜드 NZD', '체코 CZK', '칠레 CLP', '튀르키예 TRY', '몽골 MNT', '이스라엘 ILS', '덴마크 DKK', '노르웨이 NOK', '사우디아라비아 SAR', '쿠웨이트 KWD', '바레인 BHD', '아랍에미리트 AED', '요르단 JOD', '이집트 EGP', '태국 THB', '싱가포르 SGD', '말레이시아 MYR', '인도네시아 IDR 100', '카타르 QAR', '카자흐스탄 KZT', '브루나이 BND', '인도 INR', '파키스탄 PKR', '방글라데시 BDT', '필리핀 PHP', '멕시코 MXN', '브라질 BRL', '베트남 VND 100', '남아프리카 공화국 ZAR', '러시아 RUB', '헝가리 HUF', '폴란드 PLN', '스리랑카 LKR', '알제리 DZD', '케냐 KES', '콜롬비아 COP', '탄자니아 TZS', '네팔 NPR', '루마니아 RON', '리비아 LYD', '마카오 MOP', '미얀마 MMK', '에티오피아 ETB', '우즈베키스탄 UZS', '캄보디아 KHR', '피지 FJD']\n",
      "['1,240.00', '1,340.94', '962.25', '182.68', '158.56', '40.88', '1,513.42', '3,224.97', '923.37', '1,343.30', '118.69', '861.12', '791.37', '55.87', '1.51', '66.00', '0.36', '362.19', '180.25', '124.77', '330.11', '4,060.12', '3,289.82', '337.60', '1,746.85', '41.71', '37.42', '936.63', '286.61', '8.20', '340.07', '2.67', '936.63', '15.16', '5.42', '11.94', '22.59', '65.97', '240.87', '5.29', '72.29', '18.07', '3.36', '285.24', '3.37', '9.11', '9.99', '0.26', '0.53', '9.48', '271.98', '260.71', '153.87', '0.59', '23.12', '0.11', '0.30', '570.03']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as BS\n",
    "import requests as req\n",
    "\n",
    "res = req.get(\"https://finance.naver.com/marketindex/exchangeList.nhn\")\n",
    "soup = BS(res.text, 'html.parser')\n",
    "\n",
    "tds = soup.find_all(\"td\")\n",
    "\n",
    "names = []\n",
    "\n",
    "for td in tds:\n",
    "    if len(td.find_all(\"a\")) == 0:\n",
    "        continue\n",
    "    names.append(td.get_text(strip=True))\n",
    "    \n",
    "prices = []\n",
    "for td in tds:\n",
    "    if \"class\" in td.attrs:\n",
    "        if \"sale\" in td.attrs[\"class\"]:\n",
    "            prices.append(td.get_text(strip=True))\n",
    "\n",
    "print(names)\n",
    "print(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 페이지 가져오기 완료\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 빈 리스트 생성\n",
    "pages = []\n",
    "\n",
    "# 첫 페이지 번호 지정\n",
    "page_num = 1\n",
    "\n",
    "# headers 지정\n",
    "headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36',\n",
    "}\n",
    "\n",
    "while True:\n",
    "    # HTML 코드 받아오기, 위에서 지정해 준 headers 설정해 주기\n",
    "    response = requests.get(\"http://www.ssg.com/search.ssg?target=all&query=nintendo&page=\" + str(page_num), headers=headers)\n",
    "\n",
    "    # BeautifulSoup 타입으로 변환하기\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # \".csrch_tip\" 클래스가 없을 때만 HTML 코드를 리스트에 담기\n",
    "    if len(soup.select('.csrch_tip')) == 0:\n",
    "        pages.append(soup)\n",
    "        print(str(page_num) + \"번째 페이지 가져오기 완료\")\n",
    "        page_num += 1\n",
    "        time.sleep(1)\n",
    "        break #쿠키값 설정x 무한루프생성 임시로 루프탈출\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# 가져온 페이지 개수 출력하기\n",
    "print(len(pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>rank</th>\n",
       "      <th>channel</th>\n",
       "      <th>program</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009.12.28 ~ 2010.01.03</td>\n",
       "      <td>1</td>\n",
       "      <td>KBS2</td>\n",
       "      <td>주말연속극(수상한삼형제)</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009.12.28 ~ 2010.01.03</td>\n",
       "      <td>2</td>\n",
       "      <td>KBS1</td>\n",
       "      <td>일일연속극(다함께차차차)</td>\n",
       "      <td>33.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009.12.28 ~ 2010.01.03</td>\n",
       "      <td>3</td>\n",
       "      <td>KBS2</td>\n",
       "      <td>해피선데이</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009.12.28 ~ 2010.01.03</td>\n",
       "      <td>4</td>\n",
       "      <td>MBC</td>\n",
       "      <td>MBC연기대상2부</td>\n",
       "      <td>24.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009.12.28 ~ 2010.01.03</td>\n",
       "      <td>5</td>\n",
       "      <td>SBS</td>\n",
       "      <td>주말극장(천만번사랑해)</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    period rank channel        program rating\n",
       "0  2009.12.28 ~ 2010.01.03    1    KBS2  주말연속극(수상한삼형제)   33.4\n",
       "1  2009.12.28 ~ 2010.01.03    2    KBS1  일일연속극(다함께차차차)   33.1\n",
       "2  2009.12.28 ~ 2010.01.03    3    KBS2          해피선데이   27.1\n",
       "3  2009.12.28 ~ 2010.01.03    4     MBC      MBC연기대상2부   24.4\n",
       "4  2009.12.28 ~ 2010.01.03    5     SBS   주말극장(천만번사랑해)   24.2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 여기에 코드를 작성하세요\n",
    "\n",
    "records = []\n",
    "\n",
    "for year in range(2010, 2011):\n",
    "    for month in range(1, 13):\n",
    "        for week in range(0, 6):\n",
    "            quiry = \"?year={}&month={}&weekIndex={}\".format(year, month, week)\n",
    "            resp = requests.get(\"https://workey.codeit.kr/ratings/index\"+quiry)\n",
    "            page = resp.text\n",
    "            soup = BeautifulSoup(page, \"html.parser\")\n",
    "            if len(soup.select(\"td.program\")) != 0:\n",
    "                period = soup.select(\"#weekSelectBox option\")\n",
    "                rank = soup.select(\"td.rank\")\n",
    "                channel = soup.select(\"td.channel\")\n",
    "                program = soup.select(\"td.program\")\n",
    "                rating = soup.select(\"td.percent\")\n",
    "                for i in range(0, len(period)):\n",
    "                    for j in range(0, 10):\n",
    "                        record = [] \n",
    "                        record.append(period[i].text)\n",
    "                        record.append(rank[j].text)\n",
    "                        record.append(channel[j].text)\n",
    "                        record.append(program[j].text)\n",
    "                        record.append(rating[j].text)\n",
    "                        records.append(record)\n",
    "\n",
    "df = pd.DataFrame(data = records, columns=['period', 'rank', 'channel', 'program', 'rating'])\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "088249665a81e93c8036df710d5b8cf66018793aa44d5d95f913d7290e7bc9d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
